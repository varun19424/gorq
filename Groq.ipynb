{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFdZ5MAPx6APrmYCkaJym0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varun19424/gorq/blob/main/Groq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OQGk8l1COI_",
        "outputId": "4a149e6d-2bbd-47f4-89e6-9a537403b650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.4.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m572.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from groq)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, groq\n",
            "Successfully installed groq-0.4.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GROQ_API_KEY=userdata.get('groq')\n"
      ],
      "metadata": {
        "id": "JXdqIPGHCXvO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5rAbCk76Cgq1",
        "outputId": "afbc66d1-c677-4588-afc7-eac7279474d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the GROQ_API_KEY environment variable\n",
        "import os\n",
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
      ],
      "metadata": {
        "id": "_fiodnIiCjew"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq"
      ],
      "metadata": {
        "id": "ohQoK4D9DBn1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = Groq(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        ")"
      ],
      "metadata": {
        "id": "yZTlUDc9DERH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain Attention all your need\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        ")"
      ],
      "metadata": {
        "id": "_6EWKZ3iDGuy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORveFokYDrkp",
        "outputId": "900df5c2-3453-48b3-b2ed-d921aac73759"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention mechanisms are a type of model architecture used in machine learning, particularly in the field of natural language processing (NLP). The main idea behind attention is to allow the model to focus on specific parts of the input when producing an output, instead of considering the entire input sequence equally. This is especially useful for tasks such as machine translation, where the meaning of a word in a sentence can depend on its context, and the model needs to be able to refer back to earlier parts of the input sequence.\n",
            "\n",
            "There are several different types of attention mechanisms, but one of the most commonly used is called \"additive attention\" or \"scaled dot-product attention\". In this approach, the model first computes a score for each element in the input sequence, indicating how important it is for the current output. These scores are then used to compute a weighted sum of the input elements, which forms the final output.\n",
            "\n",
            "The intuition behind attention is to mimic human attention, where humans focus on certain parts of the input while ignoring others. For example, when we read a paragraph, we pay more attention to some words that are more relevant to understand the meaning of the paragraph, instead of paying equal attention to all the words.\n",
            "\n",
            "Attention mechanisms have been shown to significantly improve the performance of NLP models on a wide range of tasks, including machine translation, text summarization, and sentiment analysis. By allowing the model to focus on the most relevant parts of the input, attention mechanisms can help reduce the impact of irrelevant or noisy information, leading to more accurate and robust models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SB9QQHghDuVG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}